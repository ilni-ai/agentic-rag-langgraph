# Agentic RAG with LangGraph, Gemini, and FAISS  

This project implements a fully working **Agentic Retrieval-Augmented Generation (RAG)** system using:

- LangGraph for multi-step agent workflows  
- Gemini 2.x Flash for LLM reasoning + strict grounding  
- FAISS for fast local semantic search  
- SQLite for persistent chat memory  
- React + Vite for a clean UI with suggested follow-up questions  
- Domain guardrails to prevent out-of-scope answers  


---

## ğŸ“Š Architecture Diagram

![Agentic RAG Architecture](architecture-runtime.png)

The Mermaid source is available here:  
**[architecture.mmd](architecture.mmd)**

---

## ğŸ“ Folder Structure

```
agentic-rag-langgraph/
â”œâ”€â”€ agentic-rag-ui/                 # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ langgraph-server/               # Python backend (Flask + LangGraph)
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ rag_routes.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ langgraph_runner.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ info.txt                # Knowledge base for FAISS
â”‚   â”œâ”€â”€ faiss_index/                # Auto-generated vector index
â”‚   â”‚   â”œâ”€â”€ index.faiss
â”‚   â”‚   â””â”€â”€ index.pkl
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ cosine_similarity.py
â”‚   â”œâ”€â”€ build_vectorstore.py        # Builds vector store from info.txt
â”‚   â”œâ”€â”€ document_loader.py
â”‚   â”œâ”€â”€ memory.db                   # SQLite chat history
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â”‚
â”œâ”€â”€ anim.html                       # LangGraph execution animation
â”œâ”€â”€ diagram.html                    # Architecture diagram
â””â”€â”€ README.md
```

---

## âš™ï¸ Backend Setup (Flask + LangGraph)

### 1. Build the FAISS Vector Store

```bash
cd langgraph-server
python build_vectorstore.py
```

---

### 2. Create and activate a virtual environment

```bash
python -m venv venv
venv\Scripts\activate        # Windows
# or
source venv/bin/activate       # macOS/Linux
```

---

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

### 4. Add your Gemini API key

Create:

```
langgraph-server/.env
```

Inside:

```
GEMINI_API_KEY=your_key_here
```

---

### 5. Start the backend

```bash
python app.py
```

Runs at:

```
http://localhost:5000
```

---

## ğŸ–¥ Frontend Setup (React + Vite)

```bash
cd agentic-rag-ui
npm install
npm run dev
```

Runs at:

```
http://localhost:5173
```

---

## ğŸ§  LangGraph Agent Workflow

```
User Query
      â†“
domain_check
      â†“
retrieve
      â†“
reason
      â”œâ”€â”€ sufficient â†’ respond
      â””â”€â”€ insufficient â†’ retrieve_again â†’ respond
      â†“
reflect
      â†“
Return JSON â†’ React UI â†’ stored in SQLite
```

---

## ğŸ” Features

- Semantic retrieval (FAISS)  
- Multi-hop retrieval  
- Domain guardrails  
- Strict grounding (no hallucinations)  
- Follow-up question generation  
- Persistent conversation memory  
- React UI with markdown  
- Reset session + chat history API  

---

